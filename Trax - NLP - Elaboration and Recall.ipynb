{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About This Notebook\n",
    "\n",
    "This is a playground notebook of sorts where I can try to implement a lot of the code from the assignments from scratch.\n",
    "\n",
    "The assignments are helpful but there are too many hints and it's too easy for someone to work through them without truely understanding how transformers, attention, etc. works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terms\n",
    "\n",
    "* cross attention\n",
    "* causal attention\n",
    "* scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "\n",
    "import trax\n",
    "from trax import layers as tl\n",
    "from trax.fastmath import numpy as jnp\n",
    "\n",
    "# to print the entire np array\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Dot Product Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dp_attention(q, k, v, m, embed_dims, vocab_size):\n",
    "    '''\n",
    "    k - keys [batch, seq_len_in, embed_dims]\n",
    "    q - query [batch, seq_len_out, embed_dims]\n",
    "    v - values [batch, seq_len_in, embed_dims]\n",
    "    m - mask [batch, seq_len_out, seq_len_in]\n",
    "    '''\n",
    "    kt  = jnp.transpose(k)\n",
    "    qkt = jnp.dot(q, kt)\n",
    "    mqk = jnp.where(m==True, qtk, jnp.full_like(qkt, -1e9)) #add in the mask\n",
    "    w   = softmax(mqk/sqrt(embed_dims))\n",
    "    \n",
    "    return jnp.dot(w,v)\n",
    "    \n",
    "    #Note: it's a little unclear to me how I can use trax layers with jax.numpy operations. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax with no division or multiplication to avoid underflow and overflow. \n",
    "def softmax(x):\n",
    "    d = trax.fastmath.logsumexp(x, axis=-1, keepdims=True)\n",
    "    p = jnp.exp(x - d)\n",
    "    return p #array of probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Attention\n",
    "\n",
    "a.k.a masked-multi head attention\n",
    "\n",
    "See assignment 2. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def compute_attention_heads_closure(n_heads, d_head):\n",
    "    pass\n",
    "\n",
    "def dot_product_self_attention():\n",
    "    pass\n",
    "\n",
    "def compute_attention_output_closure():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CausalAttention():\n",
    "    \"\"\"Transformer-style multi-headed causal attention.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Encoder / Decoder with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nmt_encoder(vocab_size, embed_dims, lstm_hidden, num_lstms):\n",
    "    '''\n",
    "    Encodes the input token sequences before passing it along to attention and then on to the decoder.\n",
    "    '''\n",
    "    input_encoder = tl.Serial(\n",
    "        tl.Embedding(vocab_size, embed_dims),\n",
    "        [tl.LSTM(lstm_hidden) for _ in range(num_lstms) ],\n",
    "    )\n",
    "    \n",
    "    return input_encoder\n",
    "    \n",
    "def pre_attention_decoder(target_vocab_size, embed_dims, lstm_hidden):\n",
    "    '''\n",
    "    Decodes\" the target target token sequences. The decoder hidden state will be used as queries in the attention layers. \n",
    "    - This is just the first decoder in this model. A second decoder runs after the attention layer. \n",
    "    - Shifts the supplied token sequences right before running the layers. \n",
    "    - Note: only a single LSTM was used for the decoder vs. many for the encoder. Not really sure why. \n",
    "    '''\n",
    "    \n",
    "    pa_target_decoder = tl.Serial(\n",
    "        tl.ShiftRight(),\n",
    "        tl.Embedding(target_vocab_size, embed_dims),\n",
    "        tl.LSTM(lstm_hidden),\n",
    "    )\n",
    "    return pa_target_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention helper functions\n",
    "\n",
    "def prepare_qkv_from_encoder_decoder(encoder_activations, decoder_activations, input_token_seq):\n",
    "    '''\n",
    "    Preparing inputs for attention layer from activations of encoder and decoder hidden states.\n",
    "    Super light level of indirection that maps activations to QKV in attention.\n",
    "    '''\n",
    "    attention_heads=1\n",
    "    \n",
    "    queries = decoder_activations\n",
    "    keys    = encoder_activations\n",
    "    values  = encoder_activations\n",
    "    \n",
    "    (batch_size, seq_len) = input_token_seq.shape \n",
    "    (_, _, dec_embed_dim)   = decoder_activations.shape \n",
    "    \n",
    "    # if token is padding then mask = 0, otherwise 1\n",
    "    mask  = jnp.where(input_token_seq == 0, 0, 1)\n",
    "    \n",
    "    #mask dims transform:  batch_size x seq_len -> batch_size, attention_heads, decoder_length, encoder_length\n",
    "    \n",
    "    #add dimensions\n",
    "    mask = jnp.reshape(mask, (batch_size, 1, 1, seq_len))\n",
    "    \n",
    "    #QUESTION: is the seq_len and the encoder length the same? Maybe just the dims change. \n",
    "    \n",
    "    # adding in this way causes broadcast / dim expansion\n",
    "    mask = mask + jnp.zeros((1, attention_heads, decoder_embed_dim, 1))\n",
    "    \n",
    "    return (queries, keys, values, mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMTAttn(input_vocab_size=33300,\n",
    "            target_vocab_size=33300,\n",
    "            d_model=1024,\n",
    "            n_encoder_layers=2,\n",
    "            n_decoder_layers=2,\n",
    "            n_attention_heads=4,\n",
    "            attention_dropout=0.0,\n",
    "            mode='train'):\n",
    "    \n",
    "    tl.Serial([\n",
    "        tl.Select([0,1,0,1]),\n",
    "        tl.Parallel([\n",
    "            nmt_encoder(input_vocab_size, d_model, d_model, n_encoder_layers),\n",
    "            pre_attention_decoder(target_vocab_size, d_model, d_model),\n",
    "        ]),\n",
    "        #takes three inputs. Leaves one on stack...\n",
    "        tl.Fn('PrepareAttentionInput', prepare_qkv_from_encoder_decoder ,n_out=4),\n",
    "        \n",
    "        #https://trax-ml.readthedocs.io/en/latest/trax.layers.html#trax.layers.combinators.Residual\n",
    "        #TODO: Can you understand the Stack and Residual better? \n",
    "        tl.Residual(\n",
    "            tl.AttentionQKV(d_model, n_heads=n_attention_heads, dropout=attention_dropout, mode=mode)\n",
    "        ),\n",
    "        #this just drops the mask. \n",
    "        tl.Select([0,2]),\n",
    "        [tl.LSTM(d_model) for _ in range(n_decoder_layers)], #do you need to use d_model here? \n",
    "        tl.Dense(target_vocab_size),\n",
    "        tl.LogSoftmax()\n",
    "    ])\n",
    "\n",
    "#TODO: test me."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"NMTModel.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Model Once\n",
    "\n",
    "Test the model to make sure you understand the inputs and outputs and to make sure there are no errors in how you coded it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_symbol(NMTAttn, input_tokens, cur_output_tokens, temperature):\n",
    "    pass\n",
    "     \n",
    "#Note: you can implement the function above or pass partially translated targets to the model with a batch dim directly\n",
    "#and get a prob dist back. \n",
    "\n",
    "#Note the input is a pair like\n",
    "NMTAttn((input_tokens, padded_with_batch))\n",
    "\n",
    "#How does that work with tl.Select?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "c10 = jnp.zeros((1, 10,))\n",
    "r10 = jnp.zeros((10, 1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr10 = c10 + r10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr10.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trax Practice\n",
    "\n",
    "* TODO: read the [Layers Intro](https://trax-ml.readthedocs.io/en/latest/notebooks/layers_intro.html)\n",
    "* Try to create a CreateFirst where m is the first thing returned. What happens\n",
    "* Download the ungrade trax lab from Coursera NLP C4 W1 and experiment with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a similar network to what we have above but let's make it simple and deterministic\n",
    "\n",
    "#TODO: could you change this to work with jax DeviceArrays just to see how it works? \n",
    "\n",
    "def Addition():\n",
    "    layer_name = \"Addition\"  # don't forget to give your custom layer a name to identify\n",
    "\n",
    "    # Custom function for the custom layer\n",
    "    def func(x, y):\n",
    "        return jnp.add(x,y)\n",
    "\n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "def Multiplication():\n",
    "    layer_name = (\n",
    "        \"Multiplication\"  # don't forget to give your custom layer a name to identify\n",
    "    )\n",
    "\n",
    "    # Custom function for the custom layer\n",
    "    def func(x, y):\n",
    "        return jnp.multiply(x,y) #element-wise\n",
    "    \n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "# Simple layer to create one new argument. Similar stack effect to prepare_qkv_from_encoder_decoder\n",
    "def CreateOne():\n",
    "    layer_name = (\n",
    "        \"CreateOne\"\n",
    "    )\n",
    "\n",
    "    def func(a,b,c):\n",
    "        m = jnp.array([1000.0, 2000.0])\n",
    "        return (a, b, c, m)\n",
    "    \n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "def Divide():\n",
    "    layer_name = (\n",
    "        \"Divide\"\n",
    "    )\n",
    "\n",
    "    def func(a,b):\n",
    "        return jnp.divide(a,b)\n",
    "    \n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "def Noop():\n",
    "    layer_name = (\n",
    "        \"Noop\"\n",
    "    )\n",
    "\n",
    "    def func(a,b):\n",
    "        return (a,b)\n",
    "    \n",
    "    return tl.Fn(layer_name, func)\n",
    "\n",
    "simple = tl.Serial([\n",
    "    tl.Select([0,1,0,1,0,1,0,1,0,1]),\n",
    "    CreateOne()\n",
    "    \n",
    "])\n",
    "\n",
    "topOfStack = tl.Serial([\n",
    "    tl.Select([0,1,0,1]),\n",
    "    CreateOne(),\n",
    "    tl.Select([0], n_in=2) #wanted to set this to 4 but I get an error with any number about 2\n",
    "])\n",
    "\n",
    "invert = tl.Serial([\n",
    "    tl.Select([1,0]), # 0 references top of the stack. first position is top of new stack.  \n",
    "])\n",
    "\n",
    "invert2 = tl.Serial([\n",
    "    tl.Select([1,0]), \n",
    "    Noop(),\n",
    "])\n",
    "\n",
    "simple.n_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([1., 2.], dtype=float32),\n",
       " DeviceArray([100., 200.], dtype=float32),\n",
       " DeviceArray([1., 2.], dtype=float32),\n",
       " DeviceArray([1000., 2000.], dtype=float32),\n",
       " DeviceArray([100., 200.], dtype=float32),\n",
       " DeviceArray([1., 2.], dtype=float32),\n",
       " DeviceArray([100., 200.], dtype=float32),\n",
       " DeviceArray([1., 2.], dtype=float32),\n",
       " DeviceArray([100., 200.], dtype=float32),\n",
       " DeviceArray([1., 2.], dtype=float32),\n",
       " DeviceArray([100., 200.], dtype=float32))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_tok = jnp.array([1.0, 2.0])\n",
    "out_tok = jnp.array([100.0, 200.0])\n",
    "\n",
    "simple((in_tok, out_tok))\n",
    "\n",
    "\n",
    "#It appears that when you call serial\n",
    "# - The first argument you give it goes on the top of the stack. \n",
    "# - The last argument goes on the bottom.\n",
    "\n",
    "\n",
    "#note: in the returned output, the first x values are the ordered returned items from the last function.\n",
    "#in this case it's a,b,c,m in spots 0-3 of the returned tuple below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([1., 2.], dtype=float32),\n",
       " DeviceArray([1., 2.], dtype=float32),\n",
       " DeviceArray([1000., 2000.], dtype=float32),\n",
       " DeviceArray([100., 200.], dtype=float32))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topOfStack((in_tok, out_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([100., 200.], dtype=float32),\n",
       " DeviceArray([1., 2.], dtype=float32))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invert((in_tok, out_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([100., 200.], dtype=float32),\n",
       " DeviceArray([1., 2.], dtype=float32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this implies \n",
    "# - the first argument to the function is the top of the stack. \n",
    "# - the first returned value from a function goes in the first position on a stack. \n",
    "invert2((in_tok, out_tok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stack rules\n",
    "\n",
    "* first argument to layer is top of stack\n",
    "* first item in tuple of layer goes on top of stack.\n",
    "* 0 in `tl.Select` refers to top of stack\n",
    "* first position in input array to `tl.Select` is the top of the stack. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trax-ml",
   "language": "python",
   "name": "trax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
